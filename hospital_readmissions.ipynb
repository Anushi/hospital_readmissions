{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYD DAT 4 Project : Hospital Readmissions prediction\n",
    "\n",
    "### Overview \n",
    "\n",
    "I had an opportunity to work as a software engineer at Vanderbilt University Medical Center,US where I was involved in biomedical research projects. It is very gratifying as a computer science person to help solve interesting and challenging health care problems, which is why I choose this project.\n",
    "\n",
    "Hospital readmission means when a patient is re-admitted to a hospital within short period(usually 28/30 days)after first time or initial discharge. Such readmissions are major health care concern for most countries like US, UK, Australia and many others. This leads to increased wait times, increased medical errors resulting in risking patient safety and unncessary deaths. High readmission rate is infact an indicator of poor quality care of the hospital. It also puts huge monetary burden on the hospitals as well as the government. In this project, I want to identify patients who are likely to be readmitted to the hospital. By doing this, proper care and management of such patients can be planned by their care providers.\n",
    "\n",
    "### Goal(s) : \n",
    "Predict if a patient will be readmitted to the hospital or not?\n",
    "\n",
    "### Data set used : \n",
    "\n",
    "In order to achieve the above goal(s), I need a hospital data set that has records of all hospitalizations entries for its patients for certain number of years. It should contain information like why the patients were admitted, which department they were admitted for, how many times they were admitted, what medications they were on, what lab tests were conducted, how many days they stayed in hospital, vitals signs like heights/weights, age, race, blood pressure, smoking status, their electronic medical records, billing records, genetics data, etc.\n",
    "\n",
    "Of course, it's hard to obtain such a heterogeneous dataset which is publicly available as patient data are very confidential. Though there are quite a few data sets that contain substantial information and after going through some of them, I decided to use \"Diabetes 130-US hospitals for years 1999-2008 Data Set\".\n",
    "\n",
    "This is a public available database by Center for Clinical and Translational Research, Virginia Commonwealth University. This data is a de-identified abstract of the Health Facts database (Cerner Corporation, Kansas City, MO). It contains 10 years of diabetes patients data across 130 US hospitals.\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008\n",
    "\n",
    "### Summary of data : \n",
    "\n",
    "From the below python code, following observations are made :-\n",
    " * There are 50 features and 101766 observations(hospitalizations). \n",
    " \n",
    " \n",
    " * Each row in dataframe represents one hospital admission. On an average, there are 5 hospitalizations for each patient (patient_nbr is the de-identifed patient ID).\n",
    " \n",
    " \n",
    " * In the dataset, \"readmitted\" is the target varible with three classes :\n",
    " \n",
    " NO means never readmitted (~54% of total dataset)\n",
    " \n",
    " &lt;30 means readmitted within 30 days (~11% of total dataset)\n",
    " \n",
    " &gt;30 means readmitted after 30 days (~35% of total dataset)\n",
    "\n",
    "\n",
    " * To start with a simple binary classification model, I am grouping &lt;30 and &gt;30 classes of readmitted target varible into one class \"1\", which means the patient is readmitted anytime. And class NO is \"0\" means patient is never readmitted. Also this gives even distribution between binary classes. \n",
    " \n",
    " \n",
    " * Several patients have multiple hospitalizations, so I have used only the first admission and predict whether they will be re-admitted or not. This gives 71518 unique patient hospitalizations.\n",
    " \n",
    " \n",
    " * Numeric features are : time_in_hospital, num_medications,num_lab_procedures, num_procedures, number_outpatient, number_inpatient, number_diagnoses. \n",
    "\n",
    "\n",
    " * The average amount of time spent(time_in_hospital) in a hospital is 4 days and there is a good variation in this feature ranging from 1 day to 14 days.\n",
    " \n",
    " \n",
    " * Number of lab procedures conducted during the stay is on an average 43, and it ranges from 1 to 132.\n",
    " \n",
    " \n",
    " * The average number of medications administered is 16 with minimum 1 and maximum of 81 medications.\n",
    " \n",
    " \n",
    " * Many features have non-numeric values, e.g.: race, gender, age is in range, medications like citoglipton, insulin, diag_1, diag_2, diag_3, etc,. So need to transform them.\n",
    " \n",
    " \n",
    " * Weight feature has 97% data missing, so I will not include it. I am not sure if it makes sense to impute such large missing data. May be better off by excluding that feature for the time being.\n",
    " \n",
    "\n",
    "### Modelling techniques : \n",
    "\n",
    "* As of now I have used only numeric features for classification and used logistic regression, regularized logistic regression and decision trees methods. \n",
    "\n",
    "\n",
    "* My next step is to transform non-numeric features into categorical(nominal) values and add them into the models. Some them I think are crucial.\n",
    "\n",
    "\n",
    "* Try out other models like KNN classfication, random forests, SVM, etc.\n",
    "\n",
    "\n",
    "* Question : Several non-numeric features have more than 3 categories. Does it make sense to binarize them all to be used in classic logistic regression? Or better off using models that would accept categorical features without binarizing them?\n",
    "\n",
    "### Visualizations : \n",
    "\n",
    "Although the main goal of the project is to use a modelling technique to predict patient readmission, but if time permits I would to like make some dashboard so that hospitals or clinicians can use to visualize data for their patients.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot') # This styles the graphs in a nicer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read diabetic_data.csv into a DataFrame called 'hospital_set'\n",
    "hospital_set = pd.read_table('dataset_diabetes/diabetic_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital    ...     citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1    ...              No      No                   No   \n",
       "1                 3    ...              No      Up                   No   \n",
       "2                 2    ...              No      No                   No   \n",
       "3                 2    ...              No      Up                   No   \n",
       "4                 1    ...              No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospital_set.head()\n",
    "#hospital_set['diag_1'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encounter_id                 int64\n",
       "patient_nbr                  int64\n",
       "race                        object\n",
       "gender                      object\n",
       "age                         object\n",
       "weight                      object\n",
       "admission_type_id            int64\n",
       "discharge_disposition_id     int64\n",
       "admission_source_id          int64\n",
       "time_in_hospital             int64\n",
       "payer_code                  object\n",
       "medical_specialty           object\n",
       "num_lab_procedures           int64\n",
       "num_procedures               int64\n",
       "num_medications              int64\n",
       "number_outpatient            int64\n",
       "number_emergency             int64\n",
       "number_inpatient             int64\n",
       "diag_1                      object\n",
       "diag_2                      object\n",
       "diag_3                      object\n",
       "number_diagnoses             int64\n",
       "max_glu_serum               object\n",
       "A1Cresult                   object\n",
       "metformin                   object\n",
       "repaglinide                 object\n",
       "nateglinide                 object\n",
       "chlorpropamide              object\n",
       "glimepiride                 object\n",
       "acetohexamide               object\n",
       "glipizide                   object\n",
       "glyburide                   object\n",
       "tolbutamide                 object\n",
       "pioglitazone                object\n",
       "rosiglitazone               object\n",
       "acarbose                    object\n",
       "miglitol                    object\n",
       "troglitazone                object\n",
       "tolazamide                  object\n",
       "examide                     object\n",
       "citoglipton                 object\n",
       "insulin                     object\n",
       "glyburide-metformin         object\n",
       "glipizide-metformin         object\n",
       "glimepiride-pioglitazone    object\n",
       "metformin-rosiglitazone     object\n",
       "metformin-pioglitazone      object\n",
       "change                      object\n",
       "diabetesMed                 object\n",
       "readmitted                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the default index, data types, and shape\n",
    "#hospital_set.index\n",
    "hospital_set.dtypes\n",
    "#hospital_set.shape\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.017660e+05</td>\n",
       "      <td>1.017660e+05</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.652016e+08</td>\n",
       "      <td>5.433040e+07</td>\n",
       "      <td>2.024006</td>\n",
       "      <td>3.715642</td>\n",
       "      <td>5.754437</td>\n",
       "      <td>4.395987</td>\n",
       "      <td>43.095641</td>\n",
       "      <td>1.339730</td>\n",
       "      <td>16.021844</td>\n",
       "      <td>0.369357</td>\n",
       "      <td>0.197836</td>\n",
       "      <td>0.635566</td>\n",
       "      <td>7.422607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.026403e+08</td>\n",
       "      <td>3.869636e+07</td>\n",
       "      <td>1.445403</td>\n",
       "      <td>5.280166</td>\n",
       "      <td>4.064081</td>\n",
       "      <td>2.985108</td>\n",
       "      <td>19.674362</td>\n",
       "      <td>1.705807</td>\n",
       "      <td>8.127566</td>\n",
       "      <td>1.267265</td>\n",
       "      <td>0.930472</td>\n",
       "      <td>1.262863</td>\n",
       "      <td>1.933600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.252200e+04</td>\n",
       "      <td>1.350000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.496119e+07</td>\n",
       "      <td>2.341322e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.523890e+08</td>\n",
       "      <td>4.550514e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.302709e+08</td>\n",
       "      <td>8.754595e+07</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.438672e+08</td>\n",
       "      <td>1.895026e+08</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encounter_id   patient_nbr  admission_type_id  \\\n",
       "count  1.017660e+05  1.017660e+05      101766.000000   \n",
       "mean   1.652016e+08  5.433040e+07           2.024006   \n",
       "std    1.026403e+08  3.869636e+07           1.445403   \n",
       "min    1.252200e+04  1.350000e+02           1.000000   \n",
       "25%    8.496119e+07  2.341322e+07           1.000000   \n",
       "50%    1.523890e+08  4.550514e+07           1.000000   \n",
       "75%    2.302709e+08  8.754595e+07           3.000000   \n",
       "max    4.438672e+08  1.895026e+08           8.000000   \n",
       "\n",
       "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "count             101766.000000        101766.000000     101766.000000   \n",
       "mean                   3.715642             5.754437          4.395987   \n",
       "std                    5.280166             4.064081          2.985108   \n",
       "min                    1.000000             1.000000          1.000000   \n",
       "25%                    1.000000             1.000000          2.000000   \n",
       "50%                    1.000000             7.000000          4.000000   \n",
       "75%                    4.000000             7.000000          6.000000   \n",
       "max                   28.000000            25.000000         14.000000   \n",
       "\n",
       "       num_lab_procedures  num_procedures  num_medications  number_outpatient  \\\n",
       "count       101766.000000   101766.000000    101766.000000      101766.000000   \n",
       "mean            43.095641        1.339730        16.021844           0.369357   \n",
       "std             19.674362        1.705807         8.127566           1.267265   \n",
       "min              1.000000        0.000000         1.000000           0.000000   \n",
       "25%             31.000000        0.000000        10.000000           0.000000   \n",
       "50%             44.000000        1.000000        15.000000           0.000000   \n",
       "75%             57.000000        2.000000        20.000000           0.000000   \n",
       "max            132.000000        6.000000        81.000000          42.000000   \n",
       "\n",
       "       number_emergency  number_inpatient  number_diagnoses  \n",
       "count     101766.000000     101766.000000     101766.000000  \n",
       "mean           0.197836          0.635566          7.422607  \n",
       "std            0.930472          1.262863          1.933600  \n",
       "min            0.000000          0.000000          1.000000  \n",
       "25%            0.000000          0.000000          6.000000  \n",
       "50%            0.000000          0.000000          8.000000  \n",
       "75%            0.000000          1.000000          9.000000  \n",
       "max           76.000000         21.000000         16.000000  "
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospital_set.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     54864\n",
       ">30    35545\n",
       "<30    11357\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here \"readmitted\" is the target variable\n",
    "hospital_set.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    54864\n",
       "1    46902\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming the \"readmitted\" variable into binary outcome. \n",
    "# NO = 0 (patients are not readmitted, it could be their first/initial admission)\n",
    "# >30 = 0 (patients admitted after 30 days are not called readmitted)\n",
    "# < 30 = 1 (patients admitted within 30 days are called readmitted)\n",
    "hospital_set['readmitted'] = hospital_set['readmitted'].map({ \"<30\" : 1, \">30\" : 1,\"NO\" : 0})\n",
    "hospital_set.readmitted.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71518, 50)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here many patients have multiple encounter ids (hospitalizations). \n",
    "# For predictions, I will just take the first encounter id as first admission and \n",
    "# predict whether the patient will be readmitted next time or not.\n",
    "\n",
    "# Here I use group by function to group by the hospital_set for each patient \n",
    "# and then take minimum value for encounter id to get first admission for each patient.\n",
    "hospital_subset = hospital_set.loc[hospital_set.groupby(\"patient_nbr\")[\"encounter_id\"].idxmin()]\n",
    "hospital_subset.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hospital_subset.dropna(inplace=True)\n",
    "hospital_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRANSFORMATIONS FOR CATEGORICAL VALUES\n",
    "\n",
    "# ** Need to do for gender and race**\n",
    "\n",
    "# Age feature\n",
    "hospital_subset['Age_new'] = hospital_subset.age.map({'[0-10)':0, '[10-20)':1,'[20-30)':2,'[30-40)':4,'[40-50)':5,\n",
    "                                                              '[50-60)':6,'[60-70)':7,'[70-80)':8,'[80-90)':9,'[90-100)':10})\n",
    "Age_new_dumies = pd.get_dummies(hospital_subset.Age_new, prefix='Age_new')\n",
    "hospital_subset = pd.concat([hospital_subset, Age_new_dumies], axis=1)\n",
    "\n",
    "# admission_source and admission_type features.\n",
    "\n",
    "admission_source_dumies = pd.get_dummies(hospital_subset.admission_source_id, prefix='admission_source')\n",
    "admission_type_dumies = pd.get_dummies(hospital_subset.admission_type_id, prefix='admission_type')\n",
    "\n",
    "hospital_subset = pd.concat([hospital_subset, admission_source_dumies], axis=1)\n",
    "hospital_subset = pd.concat([hospital_subset, admission_type_dumies], axis=1)\n",
    "\n",
    "# diabetesMed feature\n",
    "hospital_subset['diabetesMed_Yes'] = hospital_subset.diabetesMed.map({'Yes':1, 'No':0})\n",
    "\n",
    "\n",
    "#max_glu_serum feature\n",
    "hospital_subset['max_glu_serum_new'] = hospital_subset.max_glu_serum.map({'None':0, '>300':1,'Norm':2,'>200':4 })\n",
    "max_glu_serum_new_dumies = pd.get_dummies(hospital_subset.max_glu_serum, prefix='max_glu_serum_new')\n",
    "hospital_subset = pd.concat([hospital_subset, max_glu_serum_new_dumies], axis=1)\n",
    "\n",
    "\n",
    "#A1Cresult feature\n",
    "hospital_subset['A1Cresult_new'] = hospital_subset.A1Cresult.map({'None':0, '>7':1,'Norm':2,'>8':4 })\n",
    "A1Cresult_new_dumies = pd.get_dummies(hospital_subset.A1Cresult_new, prefix='A1Cresult_new')\n",
    "hospital_subset = pd.concat([hospital_subset, A1Cresult_new_dumies], axis=1)\n",
    "\n",
    "\n",
    "# Medication change feature\n",
    "hospital_subset['change_Yes'] = hospital_subset.diabetesMed.map({'Ch':1, 'No':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hospital_subset['diabetesMed_Yes'] = hospital_subset.diabetesMed.map({'Yes':1, 'No':0})\n",
    "#hospital_subset.diabetesMed_Yes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transforming all medication features\n",
    "# metformin \n",
    "hospital_subset['metformin_new'] = hospital_subset.metformin.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "metformin_new_dumies = pd.get_dummies(hospital_subset.metformin_new, prefix='metformin_new')\n",
    "hospital_subset = pd.concat([hospital_subset, metformin_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['repaglinide_new'] = hospital_subset.repaglinide.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "repaglinide_new_dumies = pd.get_dummies(hospital_subset.repaglinide_new, prefix='repaglinide_new')\n",
    "hospital_subset = pd.concat([hospital_subset, repaglinide_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['nateglinide_new'] = hospital_subset.nateglinide.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "nateglinide_new_dumies = pd.get_dummies(hospital_subset.nateglinide_new, prefix='nateglinide_new')\n",
    "hospital_subset = pd.concat([hospital_subset, nateglinide_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['chlorpropamide_new'] = hospital_subset.chlorpropamide.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "chlorpropamide_new_dumies = pd.get_dummies(hospital_subset.chlorpropamide_new, prefix='chlorpropamide_new')\n",
    "hospital_subset = pd.concat([hospital_subset, chlorpropamide_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['glimepiride_new'] = hospital_subset.glimepiride.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "glimepiride_new_dumies = pd.get_dummies(hospital_subset.glimepiride_new, prefix='glimepiride_new')\n",
    "hospital_subset = pd.concat([hospital_subset, glimepiride_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['acetohexamide_new'] = hospital_subset.acetohexamide.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "acetohexamide_new_dumies = pd.get_dummies(hospital_subset.acetohexamide_new, prefix='acetohexamide_new')\n",
    "hospital_subset = pd.concat([hospital_subset, acetohexamide_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['glipizide_new'] = hospital_subset.glipizide.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "glipizide_new_dumies = pd.get_dummies(hospital_subset.glipizide_new, prefix='glipizide_new')\n",
    "hospital_subset = pd.concat([hospital_subset, glipizide_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['glyburide_new'] = hospital_subset.glyburide.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "glyburide_new_dumies = pd.get_dummies(hospital_subset.glyburide_new, prefix='glyburide_new')\n",
    "hospital_subset = pd.concat([hospital_subset, glyburide_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['tolbutamide_new'] = hospital_subset.tolbutamide.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "tolbutamide_new_dumies = pd.get_dummies(hospital_subset.tolbutamide_new, prefix='tolbutamide_new')\n",
    "hospital_subset = pd.concat([hospital_subset, tolbutamide_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['pioglitazone_new'] = hospital_subset.pioglitazone.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "pioglitazone_new_dumies = pd.get_dummies(hospital_subset.pioglitazone_new, prefix='pioglitazone_new')\n",
    "hospital_subset = pd.concat([hospital_subset, pioglitazone_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['rosiglitazone_new'] = hospital_subset.rosiglitazone.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "rosiglitazone_new_dumies = pd.get_dummies(hospital_subset.rosiglitazone_new, prefix='rosiglitazone_new')\n",
    "hospital_subset = pd.concat([hospital_subset, rosiglitazone_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['acarbose_new'] = hospital_subset.acarbose.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "acarbose_new_dumies = pd.get_dummies(hospital_subset.acarbose_new, prefix='acarbose_new')\n",
    "hospital_subset = pd.concat([hospital_subset, acarbose_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['miglitol_new'] = hospital_subset.miglitol.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "miglitol_new_dumies = pd.get_dummies(hospital_subset.miglitol_new, prefix='miglitol_new')\n",
    "hospital_subset = pd.concat([hospital_subset, miglitol_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['troglitazone_new'] = hospital_subset.troglitazone.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "troglitazone_new_dumies = pd.get_dummies(hospital_subset.troglitazone_new, prefix='troglitazone_new')\n",
    "hospital_subset = pd.concat([hospital_subset, troglitazone_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['tolazamide_new'] = hospital_subset.tolazamide.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "tolazamide_new_dumies = pd.get_dummies(hospital_subset.tolazamide_new, prefix='tolazamide_new')\n",
    "hospital_subset = pd.concat([hospital_subset, tolazamide_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['examide_new'] = hospital_subset.examide.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "examide_new_dumies = pd.get_dummies(hospital_subset.examide_new, prefix='examide_new')\n",
    "hospital_subset = pd.concat([hospital_subset, examide_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['citoglipton_new'] = hospital_subset.citoglipton.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "citoglipton_new_dumies = pd.get_dummies(hospital_subset.citoglipton_new, prefix='citoglipton_new')\n",
    "hospital_subset = pd.concat([hospital_subset, citoglipton_new_dumies], axis=1)\n",
    "\n",
    "hospital_subset['insulin_new'] = hospital_subset.insulin.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "insulin_new_dumies = pd.get_dummies(hospital_subset.insulin_new, prefix='insulin_new')\n",
    "hospital_subset = pd.concat([hospital_subset, insulin_new_dumies], axis=1)\n",
    "\n",
    "#hospital_subset['glyburide_metformin_new'] = hospital_subset.glyburide-metformin.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "#glyburid_metformin_new_dumies = pd.get_dummies(hospital_subset.glyburide_metformin_new, prefix='glyburide_metformin_new')\n",
    "\n",
    "#hospital_subset['glipizide_metformin_new'] = hospital_subset.glipizide-metformin.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "#glipizide_metformin_new_dumies = pd.get_dummies(hospital_subset.glipizide_metformin_new, prefix='glipizide_metformin_new')\n",
    "\n",
    "#hospital_subset['glimepiride_pioglitazone_new'] = hospital_subset.glimepiride-pioglitazone.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "#glimepiride_pioglitazone_new_dumies = pd.get_dummies(hospital_subset.glimepiride_pioglitazone_new, prefix='glimepiride_pioglitazone_new')\n",
    "\n",
    "#hospital_subset['metformin_rosiglitazone_new'] = hospital_subset.metformin-rosiglitazone.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "#metformin_rosiglitazone_new_dumies = pd.get_dummies(hospital_subset.metformin_rosiglitazone_new, prefix='metformin_rosiglitazone_new')\n",
    "\n",
    "#hospital_subset['metformin_pioglitazone_new'] = hospital_subset.metformin-pioglitazone.map({'None':0, 'Steady':1,'Up':2,'Down':4 })\n",
    "#metformin_pioglitazone_new_dumies = pd.get_dummies(hospital_subset.metformin_pioglitazone_new, prefix='metformin_pioglitazone_new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mapping ICD9(disease codes) to numeric values. Here I group codes by disease type.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "Circulatory_map =  Counter({})\n",
    "for i in range(390,460):\n",
    "    Circulatory_map.update({str(i): 1})\n",
    "Circulatory_map.update({'785': 1})\n",
    "\n",
    "Respiratory_map =  Counter({})\n",
    "for i in range(460,520):\n",
    "    Respiratory_map.update({str(i): 2})\n",
    "Respiratory_map.update({'786': 2})\n",
    "\n",
    "Digestive_map =  Counter({})\n",
    "for i in range(520,580):\n",
    "    Digestive_map.update({str(i): 3})\n",
    "Digestive_map.update({'787': 3})  \n",
    "\n",
    "diabetes_map = Counter({'250': 4, '250.01':4,'250.02':4,'250.03':4,'250.1':4,'250.11':4,'250.12':4,'250.13':4,\n",
    "            '250.2':4,'250.21':4,'250.22':4,'250.23':4,'250.3':4,'250.31':4,'250.32':4,'250.33':4,\n",
    "            '250.4':4,'250.41':4,'250.42':4,'250.43':4,'250.5':4,'250.51':4,'250.52':4,'250.53':4,\n",
    "            '250.6':4,'250.7':4,'250.8':4,'250.81':4,'250.82':4,'250.83':4,\n",
    "            '250.9':4,'250.91':4,'250.92':4,'250.93':4})\n",
    "\n",
    "Injury_map =  Counter({})\n",
    "for i in range(800,1000):\n",
    "    Injury_map.update({str(i): 5})\n",
    "\n",
    "\n",
    "Musculoskeletal_map =  Counter({})\n",
    "for i in range(710,740):\n",
    "    Musculoskeletal_map.update({str(i): 6})\n",
    "                           \n",
    "Genitourinary_map =  Counter({})\n",
    "for i in range(580,630):\n",
    "    Genitourinary_map.update({str(i): 7})\n",
    "Genitourinary_map.update({'788': 7})\n",
    "\n",
    "Neoplasms_map =  Counter({})\n",
    "for i in range(140,240):\n",
    "    Neoplasms_map.update({str(i): 8})\n",
    "                     \n",
    "Others_map =  Counter({})\n",
    "for i in range(240,250):\n",
    "    Others_map.update({str(i): 9})\n",
    "for i in range(251,280):\n",
    "    Others_map.update({str(i): 9})\n",
    "for i in range(680,710):\n",
    "    Others_map.update({str(i): 9})\n",
    "for i in range(001,140):\n",
    "    Others_map.update({str(i): 9})\n",
    "for i in range(291,320):\n",
    "    Others_map.update({str(i): 9}) \n",
    "for i in range(281,290):\n",
    "    Others_map.update({str(i): 9})\n",
    "for i in range(320,360):\n",
    "    Others_map.update({str(i): 9})\n",
    "for i in range(630,680):\n",
    "    Others_map.update({str(i): 9})\n",
    "for i in range(360,390):\n",
    "    Others_map.update({str(i): 9})\n",
    "for i in range(740,760):\n",
    "    Others_map.update({str(i): 9})\n",
    "Others_map.update({'782': 9})    \n",
    "\n",
    "other_disease1_map =  Counter({'E909': 9,'V07': 9,'V25': 9,'V26': 9,'V43': 9,\n",
    "            'V45': 9,'V51': 9,'V53': 9,'V54': 9,'V55': 9,\n",
    "            'V56': 9,'V57': 9,'V57': 9,'V58': 9,'V60': 9,\n",
    "            'V63': 9,'V66': 9,'V67': 9,'V63': 9,'V70': 9,'V71': 9}) \n",
    "\n",
    "All_disease_map = diabetes_map + other_disease1_map + Circulatory_map + Respiratory_map + Digestive_map + Injury_map + Musculoskeletal_map + Genitourinary_map + Neoplasms_map + Others_map\n",
    "\n",
    "#All_disease_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    21894\n",
       "9.0     9919\n",
       "2.0     9776\n",
       "3.0     6570\n",
       "4.0     5805\n",
       "5.0     4779\n",
       "6.0     4080\n",
       "7.0     3514\n",
       "8.0     2742\n",
       "Name: diag_1_map, dtype: int64"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospital_subset['diag_1_map'] = hospital_subset['diag_1'].map(All_disease_map)\n",
    "hospital_subset['diag_1_map'].head()\n",
    "hospital_subset['diag_1_map'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dummy variables for new feature diag_1_map.\n",
    "\n",
    "diag_1_map_dumies = pd.get_dummies(hospital_subset.diag_1_map, prefix='diag_1_map')\n",
    "diag_1_map_dumies.head()\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame (axis=0 means rows, axis=1 means columns)\n",
    "hospital_subset = pd.concat([hospital_subset, diag_1_map_dumies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look for any linear correlations in the data\n",
    "hospital_subset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hospital_subset.diabetesMed_Yes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_in_hospital',\n",
       " 'num_medications',\n",
       " 'num_lab_procedures',\n",
       " 'num_procedures',\n",
       " 'number_outpatient',\n",
       " 'number_inpatient',\n",
       " 'number_diagnoses',\n",
       " 'diabetesMed_Yes',\n",
       " 'admission_source_1',\n",
       " 'admission_source_2',\n",
       " 'admission_source_3',\n",
       " 'admission_source_4',\n",
       " 'admission_source_5',\n",
       " 'admission_source_6',\n",
       " 'admission_source_7',\n",
       " 'admission_source_8',\n",
       " 'admission_source_9',\n",
       " 'admission_source_10',\n",
       " 'admission_source_11',\n",
       " 'admission_source_13',\n",
       " 'admission_source_14',\n",
       " 'admission_source_17',\n",
       " 'admission_source_20',\n",
       " 'admission_source_22',\n",
       " 'admission_source_25',\n",
       " 'admission_type_1',\n",
       " 'admission_type_2',\n",
       " 'admission_type_3',\n",
       " 'admission_type_4',\n",
       " 'admission_type_5',\n",
       " 'admission_type_6',\n",
       " 'admission_type_7',\n",
       " 'admission_type_8',\n",
       " 'diag_1_map_1.0',\n",
       " 'diag_1_map_2.0',\n",
       " 'diag_1_map_3.0',\n",
       " 'diag_1_map_4.0',\n",
       " 'diag_1_map_5.0',\n",
       " 'diag_1_map_6.0',\n",
       " 'diag_1_map_7.0',\n",
       " 'diag_1_map_8.0',\n",
       " 'diag_1_map_9.0',\n",
       " 'Age_new_0',\n",
       " 'Age_new_1',\n",
       " 'Age_new_2',\n",
       " 'Age_new_4',\n",
       " 'Age_new_5',\n",
       " 'Age_new_6',\n",
       " 'Age_new_7',\n",
       " 'Age_new_8',\n",
       " 'Age_new_9',\n",
       " 'Age_new_10',\n",
       " 'max_glu_serum_new_>200',\n",
       " 'max_glu_serum_new_>300',\n",
       " 'max_glu_serum_new_None',\n",
       " 'max_glu_serum_new_Norm',\n",
       " 'A1Cresult_new_0',\n",
       " 'A1Cresult_new_1',\n",
       " 'A1Cresult_new_2',\n",
       " 'A1Cresult_new_4',\n",
       " 'metformin_new_1.0',\n",
       " 'metformin_new_2.0',\n",
       " 'metformin_new_4.0',\n",
       " 'repaglinide_new_1.0',\n",
       " 'repaglinide_new_2.0',\n",
       " 'repaglinide_new_4.0',\n",
       " 'nateglinide_new_1.0',\n",
       " 'nateglinide_new_2.0',\n",
       " 'nateglinide_new_4.0',\n",
       " 'chlorpropamide_new_1.0',\n",
       " 'chlorpropamide_new_2.0',\n",
       " 'chlorpropamide_new_4.0',\n",
       " 'glimepiride_new_1.0',\n",
       " 'glimepiride_new_2.0',\n",
       " 'glimepiride_new_4.0',\n",
       " 'acetohexamide_new_1.0',\n",
       " 'glipizide_new_1.0',\n",
       " 'glipizide_new_2.0',\n",
       " 'glipizide_new_4.0',\n",
       " 'glyburide_new_1.0',\n",
       " 'glyburide_new_2.0',\n",
       " 'glyburide_new_4.0',\n",
       " 'tolbutamide_new_1.0',\n",
       " 'pioglitazone_new_1.0',\n",
       " 'pioglitazone_new_2.0',\n",
       " 'pioglitazone_new_4.0',\n",
       " 'rosiglitazone_new_1.0',\n",
       " 'rosiglitazone_new_2.0',\n",
       " 'rosiglitazone_new_4.0',\n",
       " 'acarbose_new_1.0',\n",
       " 'acarbose_new_2.0',\n",
       " 'miglitol_new_1.0',\n",
       " 'miglitol_new_2.0',\n",
       " 'miglitol_new_4.0',\n",
       " 'troglitazone_new_1.0',\n",
       " 'tolazamide_new_1.0',\n",
       " 'insulin_new_1.0',\n",
       " 'insulin_new_2.0',\n",
       " 'insulin_new_4.0']"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature_cols = ['time_in_hospital', 'num_medications','num_lab_procedures','num_procedures','number_outpatient','number_inpatient','number_diagnoses','diabetesMed_Yes','change_Yes']\n",
    "feature_cols = ['time_in_hospital', 'num_medications','num_lab_procedures','num_procedures','number_outpatient','number_inpatient','number_diagnoses','diabetesMed_Yes']\n",
    "\n",
    "for t in admission_source_dumies:\n",
    "    feature_cols.append(t)\n",
    "\n",
    "for t in admission_type_dumies:\n",
    "    feature_cols.append(t)\n",
    "\n",
    "for t in diag_1_map_dumies:\n",
    "    feature_cols.append(t)\n",
    "\n",
    "for t in Age_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "\n",
    "for t in max_glu_serum_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in A1Cresult_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in metformin_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in repaglinide_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in nateglinide_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in chlorpropamide_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in glimepiride_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in acetohexamide_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in glipizide_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in glyburide_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in tolbutamide_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in pioglitazone_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in rosiglitazone_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in acarbose_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in miglitol_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in troglitazone_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in tolazamide_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in examide_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in citoglipton_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "for t in insulin_new_dumies:\n",
    "    feature_cols.append(t)\n",
    "#for t in glyburide-metformin_new_dumies:\n",
    " #   feature_cols.append(t)\n",
    "#for t in glipizide-metformin_new_dumies:\n",
    " #   feature_cols.append(t)\n",
    "#for t in glimepiride-pioglitazone_new_dumies:\n",
    " #   feature_cols.append(t)\n",
    "#for t in metformin-rosiglitazone_new_dumies:\n",
    " #   feature_cols.append(t)\n",
    "#for t in metformin-pioglitazone_new_dumies:\n",
    " #   feature_cols.append(t)\n",
    "    \n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use numeric features to apply logistic regression\n",
    "\n",
    "X = hospital_subset[feature_cols]\n",
    "#X = hospital_subset[feature_cols].join(admission_type_dumies.ix[:, 'admission_type_1':])\n",
    "#data = df[cols_to_keep].join(dummy_ranks.ix[:, 'prestige_2':])\n",
    "y = hospital_subset.readmitted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time_in_hospital', 0.033885877354147491),\n",
       " ('num_medications', -0.0024104534438394924),\n",
       " ('num_lab_procedures', 0.00071853106993642537),\n",
       " ('num_procedures', -0.038762389778683098),\n",
       " ('number_outpatient', 0.088940110188685431),\n",
       " ('number_inpatient', 0.45420108014575472),\n",
       " ('number_diagnoses', 0.074840920767148475),\n",
       " ('diabetesMed_Yes', 0.34136645349653294),\n",
       " ('admission_source_1', 0.24964722376433862),\n",
       " ('admission_source_2', 0.052063443956556835),\n",
       " ('admission_source_3', 0.47325285879770862),\n",
       " ('admission_source_4', -0.39943437672992982),\n",
       " ('admission_source_5', 0.0015976901794238635),\n",
       " ('admission_source_6', -0.19513214148708158),\n",
       " ('admission_source_7', 0.39972063313781703),\n",
       " ('admission_source_8', -0.70406153167607732),\n",
       " ('admission_source_9', -0.82779659195190591),\n",
       " ('admission_source_10', -0.064799245534082089),\n",
       " ('admission_source_11', -0.14837659878522627),\n",
       " ('admission_source_13', 0.0),\n",
       " ('admission_source_14', -0.36211193163353006),\n",
       " ('admission_source_17', 0.010403882908407068),\n",
       " ('admission_source_20', 1.0403331422986726),\n",
       " ('admission_source_22', -0.29932203253210155),\n",
       " ('admission_source_25', -0.38196097028799225),\n",
       " ('admission_type_1', -0.13193439872302171),\n",
       " ('admission_type_2', 0.04210900061965394),\n",
       " ('admission_type_3', -0.085663576680572617),\n",
       " ('admission_type_4', 0.1148264609356803),\n",
       " ('admission_type_5', 0.18753967178139347),\n",
       " ('admission_type_6', 0.48966348501965845),\n",
       " ('admission_type_7', -1.5269399787864495),\n",
       " ('admission_type_8', -0.24557720972163846),\n",
       " ('diag_1_map_1.0', 0.069337143791469033),\n",
       " ('diag_1_map_2.0', -0.0017536174595769913),\n",
       " ('diag_1_map_3.0', -0.05651609040752148),\n",
       " ('diag_1_map_4.0', 0.17126545944820587),\n",
       " ('diag_1_map_5.0', -0.10755285510722601),\n",
       " ('diag_1_map_6.0', -0.11284551574927268),\n",
       " ('diag_1_map_7.0', -0.16461575732836967),\n",
       " ('diag_1_map_8.0', -0.44975757107295206),\n",
       " ('diag_1_map_9.0', -0.11193804413615797),\n",
       " ('Age_new_0', -0.7221492690914153),\n",
       " ('Age_new_1', -0.12076011881328597),\n",
       " ('Age_new_2', -0.20126916358450986),\n",
       " ('Age_new_4', -0.19127344025049589),\n",
       " ('Age_new_5', -0.055271834270705547),\n",
       " ('Age_new_6', -0.011444618311705006),\n",
       " ('Age_new_7', 0.068175246873318704),\n",
       " ('Age_new_8', 0.20093373455845637),\n",
       " ('Age_new_9', 0.15330481273288546),\n",
       " ('Age_new_10', -0.27622189541881687),\n",
       " ('max_glu_serum_new_>200', -0.2887127703780934),\n",
       " ('max_glu_serum_new_>300', -0.27984351153352344),\n",
       " ('max_glu_serum_new_None', -0.29636479321968329),\n",
       " ('max_glu_serum_new_Norm', -0.2910554704499016),\n",
       " ('A1Cresult_new_0', -0.16674744237002065),\n",
       " ('A1Cresult_new_1', -0.34636820164909965),\n",
       " ('A1Cresult_new_2', -0.38257814538318291),\n",
       " ('A1Cresult_new_4', -0.26028275618413649),\n",
       " ('metformin_new_1.0', -0.14091981213991206),\n",
       " ('metformin_new_2.0', -0.25695372864967242),\n",
       " ('metformin_new_4.0', -0.1526084554904433),\n",
       " ('repaglinide_new_1.0', 0.22693740186002678),\n",
       " ('repaglinide_new_2.0', -0.019929896527802006),\n",
       " ('repaglinide_new_4.0', 0.30347472955390464),\n",
       " ('nateglinide_new_1.0', 0.019953124196419838),\n",
       " ('nateglinide_new_2.0', -0.60129375470372126),\n",
       " ('nateglinide_new_4.0', -0.061703809432864069),\n",
       " ('chlorpropamide_new_1.0', -0.06945334773567291),\n",
       " ('chlorpropamide_new_2.0', 0.45441113817099432),\n",
       " ('chlorpropamide_new_4.0', -0.24122018183643129),\n",
       " ('glimepiride_new_1.0', -0.058842871258578053),\n",
       " ('glimepiride_new_2.0', -0.10096196258187938),\n",
       " ('glimepiride_new_4.0', 0.033474167897764015),\n",
       " ('acetohexamide_new_1.0', 0.31150790839237824),\n",
       " ('glipizide_new_1.0', 0.066919907351198876),\n",
       " ('glipizide_new_2.0', 0.046453225356723096),\n",
       " ('glipizide_new_4.0', 0.15559032251044366),\n",
       " ('glyburide_new_1.0', -0.010107817227965879),\n",
       " ('glyburide_new_2.0', -0.035520881143549531),\n",
       " ('glyburide_new_4.0', 0.1651440569472456),\n",
       " ('tolbutamide_new_1.0', -0.23977375239354209),\n",
       " ('pioglitazone_new_1.0', 0.03756169462289443),\n",
       " ('pioglitazone_new_2.0', 0.27662149154373566),\n",
       " ('pioglitazone_new_4.0', 0.41586184349835553),\n",
       " ('rosiglitazone_new_1.0', 0.13121266417987934),\n",
       " ('rosiglitazone_new_2.0', -0.15016555194506329),\n",
       " ('rosiglitazone_new_4.0', -0.96726163523248887),\n",
       " ('acarbose_new_1.0', 0.23182902977400557),\n",
       " ('acarbose_new_2.0', 1.0589365883041075),\n",
       " ('miglitol_new_1.0', 0.55961234093289125),\n",
       " ('miglitol_new_2.0', 0.0),\n",
       " ('miglitol_new_4.0', 0.33763805429819493),\n",
       " ('troglitazone_new_1.0', -0.063083351817696795),\n",
       " ('tolazamide_new_1.0', -0.42680027628081013),\n",
       " ('insulin_new_1.0', -0.10650703476663824),\n",
       " ('insulin_new_2.0', -0.056329197633246453),\n",
       " ('insulin_new_4.0', 0.031701539221437917)]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a logistic regression model and examine the coefficients\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "zip(feature_cols, logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Simple logistic regression) = 0.624944071588\n",
      "ROC(Simple logistic regression) =  0.557942876222\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on testing set and calculate accuracy\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "from sklearn import metrics\n",
    "#print metrics.accuracy_score(y_test, y_pred_class)\n",
    "print 'Accuracy (Simple logistic regression) =', metrics.accuracy_score(y_test, y_pred_class)\n",
    "\n",
    "# Calculate the AUC metric\n",
    "#metrics.roc_auc_score(y_test, y_pred_class)\n",
    "print \"ROC(Simple logistic regression) = \",metrics.roc_auc_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.61173184  0.61592179  0.61592179  0.62569832  0.62150838  0.68575419\n",
      "  0.61452514  0.61592179  0.62569832  0.63128492  0.61312849  0.61312849\n",
      "  0.62430168  0.61871508  0.61452514  0.60195531  0.60195531  0.62988827\n",
      "  0.67597765  0.61731844  0.61592179  0.61731844  0.60893855  0.60614525\n",
      "  0.60614525  0.59217877  0.57960894  0.62290503  0.60335196  0.57681564\n",
      "  0.62150838  0.6424581   0.62988827  0.65034965  0.64895105  0.62657343\n",
      "  0.62657343  0.57342657  0.6041958   0.59440559  0.58881119  0.5958042\n",
      "  0.61398601  0.62657343  0.62797203  0.61398601  0.64755245  0.67132867\n",
      "  0.67272727  0.62517483  0.63216783  0.61678322  0.63496503  0.65034965\n",
      "  0.60979021  0.62797203  0.62377622  0.61818182  0.65314685  0.65174825\n",
      "  0.70769231  0.69370629  0.64755245  0.65034965  0.66013986  0.67272727\n",
      "  0.66153846  0.60699301  0.56083916  0.56083916  0.56223776  0.58461538\n",
      "  0.62237762  0.62377622  0.6         0.59160839  0.6013986   0.5986014\n",
      "  0.6041958   0.61538462  0.63216783  0.58181818  0.60979021  0.63076923\n",
      "  0.61678322  0.61904762  0.60504202  0.64005602  0.65546218  0.62464986\n",
      "  0.61064426  0.62044818  0.60644258  0.62044818  0.60084034  0.68207283\n",
      "  0.67366947  0.71148459  0.60644258  0.61344538]\n",
      "0.623134155963\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION CROSS VALIDAION \n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=100)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Readmission_NO       0.63      0.90      0.74     10756\n",
      "Readmission_YES       0.58      0.21      0.31      7124\n",
      "\n",
      "    avg / total       0.61      0.63      0.57     17880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Readmission_NO', 'Readmission_YES']\n",
    "print(classification_report(y_test, y_pred_class, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (L1 penalty) = 0.624776286353\n",
      "ROC(L1 penalty) =  0.555623055353\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Readmission_NO       0.63      0.90      0.74     10756\n",
      "Readmission_YES       0.58      0.22      0.31      7124\n",
      "\n",
      "    avg / total       0.61      0.62      0.57     17880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## Logistic Regression With L1 Penalty ##########\n",
    "# logistic regression with L1 penalty (C must be positive, smaller means more regularization)\n",
    "logreg_l1 = LogisticRegression(C=0.1, penalty='l1')\n",
    "logreg_l1.fit(X_train, y_train)\n",
    "logreg_l1.coef_\n",
    "y_pred_l1 = logreg_l1.predict(X_test)\n",
    "\n",
    "# Access accuracy\n",
    "print 'Accuracy (L1 penalty) =', metrics.accuracy_score(y_test, y_pred_l1)\n",
    "print \"ROC(L1 penalty) = \",metrics.roc_auc_score(y_test, y_pred_l1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_l1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (L2 penalty) = 0.625559284116\n",
      "ROC(L2 penalty) =  0.558027625807\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Readmission_NO       0.63      0.89      0.74     10756\n",
      "Readmission_YES       0.58      0.23      0.32      7124\n",
      "\n",
      "    avg / total       0.61      0.63      0.58     17880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## Logistic Regression With L2 Penalty ##########\n",
    "# logistic regression with L2 penalty (C must be positive, smaller means more regularization)\n",
    "logreg_l2 = LogisticRegression(C=0.1, penalty='l2')\n",
    "logreg_l2.fit(X_train, y_train)\n",
    "logreg_l2.coef_\n",
    "y_pred_l2 = logreg_l2.predict(X_test)\n",
    "\n",
    "# Access accuracy\n",
    "print 'Accuracy (L2 penalty) =', metrics.accuracy_score(y_test, y_pred_l2)\n",
    "print \"ROC(L2 penalty) = \",metrics.roc_auc_score(y_test, y_pred_l2)\n",
    "\n",
    "print(classification_report(y_test, y_pred_l2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (L1 penalty) = 0.625279642058\n",
      "ROC(L1 penalty) =  0.555140841438\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Readmission_NO       0.63      0.90      0.74     10756\n",
      "Readmission_YES       0.58      0.21      0.31      7124\n",
      "\n",
      "    avg / total       0.61      0.63      0.57     17880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## Logistic Regression CV (grid search) With L1 Penalty ##########\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "seed = np.random.seed(789)\n",
    "logregCV_l1 = LogisticRegressionCV(cv=5,penalty='l1',solver='liblinear',scoring='roc_auc',random_state=seed)\n",
    "logregCV_l1.fit(X_train, y_train)\n",
    "logregCV_l1.coef_\n",
    "y_pred_l1 = logregCV_l1.predict(X_test)\n",
    "\n",
    "# Access accuracy\n",
    "print 'Accuracy (L1 penalty) =', metrics.accuracy_score(y_test, y_pred_l1)\n",
    "print \"ROC(L1 penalty) = \",metrics.roc_auc_score(y_test, y_pred_l1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_l1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########## Logistic Regression CV (grid search) With L2 Penalty ##########\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "seed = np.random.seed(789)\n",
    "#logregCV_l1 = LogisticRegressionCV(Cs=0.1,cv=5,penalty='l1',solver='liblinear',scoring='roc_auc',random_state=seed)\n",
    "logregCV_l2 = LogisticRegressionCV(cv=5,penalty='l2')\n",
    "logregCV_l2.fit(X_train, y_train)\n",
    "logregCV_l2.coef_\n",
    "y_pred_l2 = logregCV_l2.predict(X_test)\n",
    "\n",
    "# Access accuracy\n",
    "print 'Accuracy (L2 penalty) =', metrics.accuracy_score(y_test, y_pred_l2)\n",
    "print \"ROC(L2 penalty) = \",metrics.roc_auc_score(y_test, y_pred_l2)\n",
    "\n",
    "print(classification_report(y_test, y_pred_l2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Descision tree) = 0.625503355705\n",
      "ROC(Descision tree) =  0.560043005912\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Readmission_NO       0.64      0.88      0.74     10756\n",
      "Readmission_YES       0.57      0.24      0.34      7124\n",
      "\n",
      "    avg / total       0.61      0.63      0.58     17880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision trees\n",
    "from sklearn import tree\n",
    "\n",
    "# Create a decision tree classifier instance (start out with a small tree for interpretability)\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=6)\n",
    "\n",
    "# Fit the decision tree classifier\n",
    "ctree.fit(X_train, y_train)\n",
    "\n",
    "# Which features are the most important?\n",
    "ctree.feature_importances_\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = ctree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "metrics.accuracy_score(y_test, preds)\n",
    "print 'Accuracy (Descision tree) =', metrics.accuracy_score(y_test, preds)\n",
    "\n",
    "# Make predictions on the test set using predict_proba\n",
    "probs = ctree.predict_proba(X_test)\n",
    "\n",
    "# Calculate the AUC metric\n",
    "print \"ROC(Descision tree) = \",metrics.roc_auc_score(y_test, preds)\n",
    "\n",
    "print(classification_report(y_test, preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conduct a grid search for the best tree depth\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, criterion='gini')\n",
    "depth_range = range(1, 30)\n",
    "param_grid = dict(max_depth=depth_range)\n",
    "grid = GridSearchCV(ctree, param_grid, cv=5, scoring='roc_auc')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check out the scores of the grid search\n",
    "grid_mean_scores = [result[1] for result in grid.grid_scores_]\n",
    "\n",
    "\n",
    "# Plot the results of the grid search\n",
    "plt.figure()\n",
    "plt.plot(depth_range, grid_mean_scores)\n",
    "plt.hold(True)\n",
    "plt.grid(True)\n",
    "plt.plot(grid.best_params_['max_depth'], grid.best_score_, 'ro', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best = grid.best_estimator_\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Descision tree) = 0.624384787472\n",
      "ROC(Descision tree) =  0.557122525296\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Readmission_NO       0.63      0.89      0.74     10756\n",
      "Readmission_YES       0.57      0.23      0.32      7124\n",
      "\n",
      "    avg / total       0.61      0.62      0.57     17880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ctree = tree.DecisionTreeClassifier(random_state=1, criterion='gini',max_depth=7)\n",
    "\n",
    "ctree.fit(X_train, y_train)\n",
    "\n",
    "# Fit the decision tree classifier\n",
    "ctree.predict(X_test)\n",
    "# Make predictions on the test set\n",
    "preds = ctree.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print 'Accuracy (Descision tree) =', metrics.accuracy_score(y_test, preds)\n",
    "\n",
    "# Calculate the AUC metric\n",
    "print \"ROC(Descision tree) = \",metrics.roc_auc_score(y_test, preds)\n",
    "\n",
    "print(classification_report(y_test, preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=10000000000.00\n",
      " \n",
      "Mean AUC Score with L1 penalty: 0.6317\n",
      " \n",
      "Mean AUC Score with L2 penalty: 0.6295\n",
      "C=100.00\n",
      " \n",
      "Mean AUC Score with L1 penalty: 0.6317\n",
      " \n",
      "Mean AUC Score with L2 penalty: 0.6293\n",
      "C=1.00\n",
      " \n",
      "Mean AUC Score with L1 penalty: 0.6317\n",
      " \n",
      "Mean AUC Score with L2 penalty: 0.6296\n",
      "The average AUC score for for L1 Penalty is 0.631692799421\n",
      "The average AUC score for for L2 Penalty is 0.629491784335\n",
      " \n",
      "[0.63166955309472872, 0.6316693749811193, 0.6317394701871144]\n",
      " \n",
      "[0.62950614793340132, 0.62932033396782616, 0.62964887110483692]\n",
      " \n",
      "0:00:46.305000\n"
     ]
    }
   ],
   "source": [
    "# Fitting a standard logistic regression model\n",
    "# C is a cutoff for coefficients. The higher it is, the less the amount of regularisation. \n",
    "# So we set it very high first which is equivalent to no regularisation\n",
    "# def __logreg__(n):\n",
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "n=5\n",
    "AUC1 = []\n",
    "AUC2 = []\n",
    "for i , C in enumerate((1e10,1e2,1)):\n",
    "    c = int(C)\n",
    "    # Turn down tolerance iteratively. Lower tolerance means increased chance of zero coefficients\n",
    "    # L1 and L2 setup\n",
    "    logreg1 = LogisticRegressionCV(Cs=[C],cv=n,penalty='l1',solver='liblinear',scoring='roc_auc',random_state=seed) \n",
    "    logreg2 = LogisticRegressionCV(Cs=[c],cv=n,penalty='l2',scoring='roc_auc',random_state=seed)\n",
    "    # fit the models\n",
    "    logreg1.fit(X_train, y_train)\n",
    "    logreg2.fit(X_train, y_train)\n",
    "    # Calculate the mean roc_auc score\n",
    "    score1 = logreg1.scores_\n",
    "    score2 = logreg2.scores_\n",
    "    \n",
    "    meanval1 = sum(score1.values()[0])/float(len(score1.values()[0]))\n",
    "    meanval2 = sum(score2.values()[0])/float(len(score2.values()[0]))\n",
    "    \n",
    "    print \"C=%.2f\" % C\n",
    "    print \" \"\n",
    "    print \"Mean AUC Score with L1 penalty: %.4f\" % meanval1[0]\n",
    "    print \" \"\n",
    "    print \"Mean AUC Score with L2 penalty: %.4f\" % meanval2[0]\n",
    "        \n",
    "    AUC1.append(meanval1[0])\n",
    "    AUC2.append(meanval2[0])\n",
    "    \n",
    "\n",
    "\n",
    "print \"The average AUC score for for L1 Penalty is\" , np.mean(AUC1)\n",
    "print \"The average AUC score for for L2 Penalty is\" , np.mean(AUC2)\n",
    "print \" \" \n",
    "print AUC1\n",
    "print \" \"\n",
    "print AUC2\n",
    "print \" \"\n",
    "print datetime.now() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61204742906148624"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import class, instantiate estimator, fit with all data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#rfclf = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1)\n",
    "rfclf = RandomForestClassifier(n_estimators=100,oob_score=True)\n",
    "rfclf.fit(X_train, y_train)\n",
    "\n",
    "# compute the feature importances\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':rfclf.feature_importances_})\n",
    "\n",
    "# compute the out-of-bag classification accuracy\n",
    "rfclf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99988813900592866"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
